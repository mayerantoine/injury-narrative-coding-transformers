{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a SageMaker Pipeline to train and register the injury narrative BERT classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install tensorflow\n",
    "!pip install transformers\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import activations, optimizers, losses\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import joblib \n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cdc-cdh-sagemaker-s3fs-dev'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket = 'cdc-cdh-sagemaker-s3fs-dev'\n",
    "sagemaker_session = sagemaker.Session(default_bucket=bucket)\n",
    "role = sagemaker.get_execution_role()\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "default_bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pipeline name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timestamp = int(time.time())\n",
    "\n",
    "pipeline_name = 'BERT-pipeline-{}'.format(timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Dataset and preprocessing step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://cdc-cdh-sagemaker-s3fs-dev/projects/project006/injury-data/raw'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = 'projects/project006/injury-data/raw'\n",
    "input_data_train = sagemaker_session.upload_data(path = './data/raw',\n",
    "                                                      bucket = bucket,\n",
    "                                                      key_prefix = prefix)\n",
    "input_data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure pre-processing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    "    ParameterFloat,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 params\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=\"ml.c5.2xlarge\"\n",
    ")\n",
    "\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\",\n",
    "    default_value=1\n",
    ")\n",
    "\n",
    "train_percentage = ParameterFloat(\n",
    "    name=\"TrainPercentage\",\n",
    "    default_value=0.05,\n",
    ")\n",
    "\n",
    "is_sample_dataset = ParameterString(\n",
    "    name=\"SampleDataset\",\n",
    "    default_value=\"True\",\n",
    ")\n",
    "input_data = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=input_data_train,\n",
    ")\n",
    "\n",
    "transformer_model = ParameterString(\n",
    "    name=\"TransformerModel\",\n",
    "    default_value='bert-base-uncased',\n",
    ")\n",
    "max_seq_length = ParameterInteger(\n",
    "    name=\"MaxSeqLength\",\n",
    "    default_value=45,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us-east-1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker_session.boto_region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "processor = SKLearnProcessor(\n",
    "    framework_version='0.23-1',\n",
    "    role=role,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    env={'AWS_DEFAULT_REGION': sagemaker_session.boto_region_name},                             \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProcessingStep(name='Pre-Processing', step_type=<StepTypeEnum.PROCESSING: 'Processing'>, depends_on=None)\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "\n",
    "processing_inputs=[\n",
    "    ProcessingInput(\n",
    "        input_name='raw-input-data',\n",
    "        source=input_data,\n",
    "        destination='/opt/ml/processing/input/data/',\n",
    "        s3_data_distribution_type='ShardedByS3Key'\n",
    "    )\n",
    "]\n",
    "\n",
    "processing_outputs=[\n",
    "    ProcessingOutput(output_name='processed-train',\n",
    "                     source='/opt/ml/processing/output/processed/train',\n",
    "                     s3_upload_mode='EndOfJob'),\n",
    "    ProcessingOutput(output_name='processed-validation',\n",
    "                     source='/opt/ml/processing/output/processed/validation',\n",
    "                     s3_upload_mode='EndOfJob')\n",
    "]        \n",
    "\n",
    "processing_step = ProcessingStep(\n",
    "    name='Pre-Processing', \n",
    "    code='./src/pre-processing.py',\n",
    "    processor=processor,\n",
    "    inputs=processing_inputs,\n",
    "    outputs=processing_outputs,\n",
    "    job_arguments=['--train_percentage', str(train_percentage.default_value),                   \n",
    "                   '--is_sample_dataset', str(is_sample_dataset.default_value),\n",
    "                   '--max_len',str(max_seq_length.default_value),\n",
    "                   '--transformer_model',str(transformer_model.default_value)\n",
    "                  ]\n",
    ")        \n",
    "\n",
    "print(processing_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"AppSpecification\": \"<sagemaker.workflow.properties.Properties object at 0x7fb12de7c6d0>\",\n",
      "    \"AutoMLJobArn\": \"<sagemaker.workflow.properties.Properties object at 0x7fb12de7ce50>\",\n",
      "    \"CreationTime\": \"<sagemaker.workflow.properties.Properties object at 0x7fb12de7cdd0>\",\n",
      "    \"Environment\": \"<sagemaker.workflow.properties.Properties object at 0x7fb12de7c850>\",\n",
      "    \"ExitMessage\": \"<sagemaker.workflow.properties.Properties object at 0x7fb12de7cc90>\",\n",
      "    \"ExperimentConfig\": \"<sagemaker.workflow.properties.Properties object at 0x7fb12de7ca90>\",\n",
      "    \"FailureReason\": \"<sagemaker.workflow.properties.Properties object at 0x7fb12de7ccd0>\",\n",
      "    \"LastModifiedTime\": \"<sagemaker.workflow.properties.Properties object at 0x7fb12de7cd90>\",\n",
      "    \"MonitoringScheduleArn\": \"<sagemaker.workflow.properties.Properties object at 0x7fb12de7ce10>\",\n",
      "    \"NetworkConfig\": \"<sagemaker.workflow.properties.Properties object at 0x7fb12de7c950>\",\n",
      "    \"ProcessingEndTime\": \"<sagemaker.workflow.properties.Properties object at 0x7fb12de7cd10>\",\n",
      "    \"ProcessingInputs\": \"<sagemaker.workflow.properties.PropertiesList object at 0x7fb12de7c4d0>\",\n",
      "    \"ProcessingJobArn\": \"<sagemaker.workflow.properties.Properties object at 0x7fb12de7cb50>\",\n",
      "    \"ProcessingJobName\": \"<sagemaker.workflow.properties.Properties object at 0x7fb12de7c550>\",\n",
      "    \"ProcessingJobStatus\": \"<sagemaker.workflow.properties.Properties object at 0x7fb12de7cc50>\",\n",
      "    \"ProcessingOutputConfig\": \"<sagemaker.workflow.properties.Properties object at 0x7fb12de7c510>\",\n",
      "    \"ProcessingResources\": \"<sagemaker.workflow.properties.Properties object at 0x7fb12de7c610>\",\n",
      "    \"ProcessingStartTime\": \"<sagemaker.workflow.properties.Properties object at 0x7fb12de7cd50>\",\n",
      "    \"RoleArn\": \"<sagemaker.workflow.properties.Properties object at 0x7fb12de7c990>\",\n",
      "    \"StoppingCondition\": \"<sagemaker.workflow.properties.Properties object at 0x7fb12de7c650>\",\n",
      "    \"TrainingJobArn\": \"<sagemaker.workflow.properties.Properties object at 0x7fb12de7ce90>\",\n",
      "    \"_path\": \"Steps.Pre-Processing\",\n",
      "    \"_shape_names\": [\n",
      "        \"DescribeProcessingJobResponse\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# print out the list of the processing job properties\n",
    "print(json.dumps(\n",
    "    processing_step.properties.__dict__,\n",
    "    indent=4, sort_keys=True, default=str\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"AppManaged\": \"<sagemaker.workflow.properties.Properties object at 0x7fb134062b10>\",\n",
      "    \"FeatureStoreOutput\": \"<sagemaker.workflow.properties.Properties object at 0x7fb13489ad50>\",\n",
      "    \"OutputName\": \"<sagemaker.workflow.properties.Properties object at 0x7fb13489ac50>\",\n",
      "    \"S3Output\": \"<sagemaker.workflow.properties.Properties object at 0x7fb13489a1d0>\",\n",
      "    \"_path\": \"Steps.Pre-Processing.ProcessingOutputConfig.Outputs['processed-train']\",\n",
      "    \"_shape_names\": [\n",
      "        \"ProcessingOutput\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(\n",
    "    processing_step.properties.ProcessingOutputConfig.Outputs['processed-train'].__dict__, \n",
    "    indent=4, sort_keys=True, default=str\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"__str__\": \"S3Uri\",\n",
      "    \"_path\": \"Steps.Pre-Processing.ProcessingOutputConfig.Outputs['processed-train'].S3Output.S3Uri\",\n",
      "    \"_shape_names\": [\n",
      "        \"S3Uri\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(\n",
    "    processing_step.properties.ProcessingOutputConfig.Outputs['processed-train'].S3Output.S3Uri.__dict__,\n",
    "    indent=4, sort_keys=True, default=str\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Training Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12 params\n",
    "\n",
    "epochs = ParameterInteger(\n",
    "    name=\"Epochs\",\n",
    "    default_value=3\n",
    ")\n",
    "\n",
    "num_records = ParameterInteger(\n",
    "    name=\"NumRecords\"\n",
    ")\n",
    "   \n",
    "\n",
    "learning_rate = ParameterFloat(\n",
    "    name=\"LearningRate\",\n",
    "    default_value=5e-5\n",
    ") \n",
    "    \n",
    "train_batch_size = ParameterInteger(\n",
    "    name=\"TrainBatchSize\",\n",
    "    default_value=16\n",
    ")\n",
    "\n",
    "train_steps_per_epoch = ParameterInteger(\n",
    "    name=\"TrainStepsPerEpoch\",\n",
    "    default_value=500\n",
    ")\n",
    "\n",
    "validation_batch_size = ParameterInteger(\n",
    "    name=\"ValidationBatchSize\",\n",
    "    default_value=16\n",
    ")\n",
    "\n",
    "validation_steps_per_epoch = ParameterInteger(\n",
    "    name=\"ValidationStepsPerEpoch\",\n",
    "    default_value=500\n",
    ")\n",
    "\n",
    "\n",
    "train_instance_count = ParameterInteger(\n",
    "    name=\"TrainInstanceCount\",\n",
    "    default_value=1\n",
    ")\n",
    "\n",
    "train_instance_type = ParameterString(\n",
    "    name=\"TrainInstanceType\",\n",
    "    default_value=\"ml.p3.2xlarge\"\n",
    ")\n",
    "\n",
    "\n",
    "max_seq_length = ParameterInteger(\n",
    "    name=\"MaxSeqLength\",\n",
    "    default_value=45,\n",
    ")\n",
    "\n",
    "optimizer = ParameterString(\n",
    "    name=\"optimizer\",\n",
    "    default_value='Adam'\n",
    ")\n",
    "\n",
    "input_mode = ParameterString(\n",
    "    name=\"InputMode\",\n",
    "    default_value=\"File\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters={\n",
    "    'max_seq_length': max_seq_length,\n",
    "    'epochs': epochs,\n",
    "    'num_records':num_records\n",
    "    'learning_rate': learning_rate,\n",
    "    'batch_size': train_batch_size,\n",
    "    'steps_per_epoch': train_steps_per_epoch,\n",
    "    'validation_batch_size': validation_batch_size,\n",
    "    'validation_steps': validation_steps_per_epoch,\n",
    "    'optimizer':optimizer\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [{'Name':'train:loss','Regex':'loss: ([0-9\\\\.]+)'},\n",
    "                                    {'Name':'train:accuracy','Regex':'acc: ([0-9\\\\.]+)'},\n",
    "                                    {'Name':'validation:loss','Regex':'val_loss: ([0-9\\\\.]+)'},\n",
    "                                    {'Name':'validation:accuracy','Regex':'val_acc: ([0-9\\\\.]+)'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "estimator = HuggingFace(\n",
    "        entry_point=\"train.py\",\n",
    "        source_dir = \"./src/\",\n",
    "        role=role,\n",
    "        instance_count=train_instance_count,\n",
    "        volume_size = 50,\n",
    "        max_run = 18000,\n",
    "        instance_type=train_instance_type,\n",
    "        transformers_version = \"4.4\",\n",
    "        tensorflow_version  = \"2.4\",\n",
    "        py_version=\"py37\",\n",
    "        hyperparameters = hyperparameters,\n",
    "        metric_definitions = metric_definitions,\n",
    "        enable_sagemaker_metrics = True\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.steps import CacheConfig\n",
    "\n",
    "cache_config = CacheConfig(enable_caching=True, expire_after=\"PT1H\") # PT1H represents `one hour`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingStep(name='Train', step_type=<StepTypeEnum.TRAINING: 'Training'>, depends_on=None)\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "training_step = TrainingStep(\n",
    "    name='Train',\n",
    "    estimator=estimator,\n",
    "    inputs={\n",
    "        'train': TrainingInput(\n",
    "            s3_data=processing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'processed-train'\n",
    "            ].S3Output.S3Uri\n",
    "        ),\n",
    "        'validation': TrainingInput(\n",
    "            s3_data=processing_step.properties.ProcessingOutputConfig.Outputs[\n",
    "                'processed-validation'\n",
    "            ].S3Output.S3Uri\n",
    "        )\n",
    "    },\n",
    "    cache_config=cache_config\n",
    ")\n",
    "\n",
    "print(training_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "evaluation_processor = SKLearnProcessor(\n",
    "    framework_version='0.23-1',\n",
    "    role=role,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    env={'AWS_DEFAULT_REGION': region},\n",
    "    max_runtime_in_seconds=7200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name='EvaluationReport',\n",
    "    output_name='metrics',\n",
    "    path='evaluation.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "evaluation_step = ProcessingStep(\n",
    "    name='EvaluateModel',\n",
    "    processor=evaluation_processor,\n",
    "    code='src/evaluate_model_metrics.py',\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination='/opt/ml/processing/input/model'\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=processing_step.properties.ProcessingOutputConfig.Outputs['processed-validation'].S3Output.S3Uri,\n",
    "            destination='/opt/ml/processing/input/data'\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name='metrics', \n",
    "                         s3_upload_mode='EndOfJob',\n",
    "                         source='/opt/ml/processing/output/metrics/'),\n",
    "    ],\n",
    "    job_arguments=[\n",
    "        '--max-seq-length', str(max_seq_length.default_value),\n",
    "    ],\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register model step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 parameters\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\",\n",
    "    default_value=\"PendingManualApproval\"\n",
    ")\n",
    "\n",
    "deploy_instance_type = ParameterString(\n",
    "    name=\"DeployInstanceType\",\n",
    "    default_value=\"ml.m5.large\"\n",
    ")\n",
    "\n",
    "deploy_instance_count = ParameterInteger(\n",
    "    name=\"DeployInstanceCount\",\n",
    "    default_value=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_group_name = f\"BERT-Reviews-{timestamp}\"\n",
    "\n",
    "print(model_package_group_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics \n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=\"{}/evaluation.json\".format(\n",
    "            evaluation_step.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "        ),\n",
    "        content_type=\"application/json\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(model_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define deployment image for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"tensorflow\",\n",
    "    region=region,\n",
    "    version=\"2.4.0\",\n",
    "    py_version=\"py37\",\n",
    "    instance_type=deploy_instance_type,\n",
    "    image_scope=\"inference\"\n",
    ")\n",
    "print(inference_image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "register_step = RegisterModel(\n",
    "    name=\"RegisterModel\",\n",
    "    estimator=estimator,\n",
    "    image_uri=inference_image_uri, # Replace None \n",
    "    model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"application/jsonlines\"],\n",
    "    response_types=[\"application/jsonlines\"],\n",
    "    inference_instances=[deploy_instance_type],\n",
    "    transform_instances=[deploy_instance_type], # batch transform is not used in this lab\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "\n",
    "model_name = 'bert-model-{}'.format(timestamp)\n",
    "\n",
    "model = Model(\n",
    "    name=model_name,\n",
    "    image_uri=inference_image_uri, # Replace None\n",
    "    model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import CreateModelInput\n",
    "\n",
    "create_inputs = CreateModelInput(\n",
    "    instance_type=deploy_instance_type, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.steps import CreateModelStep\n",
    "\n",
    "create_step = CreateModelStep(\n",
    "    name=\"CreateModel\",\n",
    "    model=model, # Replace None\n",
    "    inputs=create_inputs, # Replace None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Check accuracy condition step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_accuracy_value = ParameterFloat(\n",
    "    name=\"MinAccuracyValue\",\n",
    "    default_value=0.85 # random choice from three classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import (\n",
    "    ConditionStep,\n",
    "    JsonGet,\n",
    ")\n",
    "\n",
    "minimum_accuracy_condition = ConditionGreaterThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step=evaluation_step,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"metrics.accuracy.value\",\n",
    "    ),\n",
    "    right=min_accuracy_value # minimum accuracy threshold\n",
    ")\n",
    "\n",
    "minimum_accuracy_condition_step = ConditionStep(\n",
    "    name=\"AccuracyCondition\",\n",
    "    conditions=[minimum_accuracy_condition],\n",
    "    if_steps=[register_step, create_step], # successfully exceeded or equaled the minimum accuracy, continue with model registration\n",
    "    else_steps=[], # did not exceed the minimum accuracy, the model will not be registered\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        input_data,\n",
    "        processing_instance_count,\n",
    "        processing_instance_type,\n",
    "        max_seq_length,\n",
    "        is_sample_dataset,\n",
    "        transformer_model,\n",
    "        train_percentage,\n",
    "        \n",
    "        epochs,\n",
    "        num_records,\n",
    "        learning_rate,\n",
    "        optimizer,\n",
    "        train_batch_size,\n",
    "        train_steps_per_epoch,\n",
    "        validation_batch_size,\n",
    "        validation_steps_per_epoch,\n",
    "        input_mode,\n",
    "        train_instance_count,\n",
    "        train_instance_type,   \n",
    "        \n",
    "        min_accuracy_value,\n",
    "        \n",
    "        model_approval_status,\n",
    "        deploy_instance_type,\n",
    "        deploy_instance_count\n",
    "    ],\n",
    "    steps=[processing_step, training_step, evaluation_step, minimum_accuracy_condition_step],\n",
    "    sagemaker_session=sess,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "definition = json.loads(pipeline.definition())\n",
    "\n",
    "pprint(definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = pipeline.create(role_arn=role)\n",
    "\n",
    "pipeline_arn = response[\"PipelineArn\"]\n",
    "print(pipeline_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start(\n",
    "    parameters=dict(\n",
    "        InputData=raw_input_data_s3_uri,\n",
    "        ProcessingInstanceCount=1,\n",
    "        ProcessingInstanceType='ml.c5.2xlarge',\n",
    "        MaxSeqLength=45,\n",
    "        SampleDataset='True',\n",
    "        TransformerModel = 'bert-based-uncased',\n",
    "        TrainPercentage=0.9,\n",
    "        Epochs=3,\n",
    "        num_records = 138549,\n",
    "        LearningRate=5e-5,\n",
    "        optimizer = 'Adam'\n",
    "        TrainBatchSize=16,,\n",
    "        TrainStepsPerEpoch=50,\n",
    "        ValidationBatchSize=16,\n",
    "        ValidationStepsPerEpoch=64,\n",
    "        InputMode= 'File',\n",
    "        TrainInstanceCount=1,\n",
    "        TrainInstanceType='ml.p3.2xlarge',\n",
    "        MinAccuracyValue=0.75,\n",
    "        ModelApprovalStatus='PendingManualApproval', \n",
    "        DeployInstanceType='ml.m5.large',\n",
    "        DeployInstanceCount=1 \n",
    "    )\n",
    ")\n",
    "\n",
    "print(execution.arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
